image: python:3.7

variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_DRIVER: overlay2
  GIT_SUBMODULE_STRATEGY: recursive

test:
  stage: test
  services:
    - docker:19.03.5-dind
  before_script:
    - curl -Lo /tmp/docker.tgz https://download.docker.com/linux/static/stable/x86_64/docker-19.03.5.tgz && tar -xf /tmp/docker.tgz -C /usr/local && rm /tmp/docker.tgz && export PATH=/usr/local/docker:$PATH && export DOCKER_HOST=tcp://docker:2375
    - docker info
    - curl -Lo /usr/local/bin/docker-compose "https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)"
    - chmod +x /usr/local/bin/docker-compose
    - curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python - --version 1.0.10 && /root/.poetry/bin/poetry config virtualenvs.create false
    # Important note about this: the Docker server is on a separate host,
    # so exposed ports are at 'docker' not 'localhost', and
    # Docker containers can't reach the local runner!
  script:
    - diff -u lib_core/datamart_core/types.py lib_profiler/datamart_profiler/types.py
    - diff -u lib_core/datamart_core/types.py lib_materialize/datamart_materialize/types.py
    - /root/.poetry/bin/poetry install
    - |
      # Check READMEs
      find . -name README.rst | while read i; do
        python -m readme_renderer "$i" >/dev/null
      done

    # Build base image, using the GitLab registry as a cache
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN registry.gitlab.com
    - |
      # Pull the base image so we don't have to build from scratch
      docker pull $CI_REGISTRY_IMAGE/base || true
      # Update the base image (maybe)
      chmod 644 poetry.lock docker/install_deps.py
      touch -t 200001010000.00 poetry.lock docker/install_deps.py
      docker build -t datamart_base . \
        --cache-from=$CI_REGISTRY_IMAGE/base \
        -f base.Dockerfile
      # Push the updated image to the registry (might be no-op)
      docker tag datamart_base $CI_REGISTRY_IMAGE/base
      docker push $CI_REGISTRY_IMAGE/base

    # Set up environment for testing
    - cp tests/ci.env .env
    - . scripts/load_env.sh
    - "sed -i 's/# CI: //' docker-compose.yml base.Dockerfile */Dockerfile"
    - "sed -i '/# NOTCI$/d' docker-compose.yml base.Dockerfile */Dockerfile"
    - "sed -i 's/127\\.0\\.0\\.1:\\([0-9]\\+\\):\\([0-9]\\+\\)/\\1:\\2/' docker-compose.yml"
    - mkdir cov
    - chown 998 cov

    # Download lib_geo data
    - python -m datamart_geo --update lib_geo/data/

    # Build images
    - python scripts/docker-compose-cached-build.py apiserver apilb coordinator profiler test-discoverer
    - docker-compose pull rabbitmq  # Don't build it

    # Bring services up
    - scripts/setup.sh
    - docker-compose up -d elasticsearch rabbitmq redis
    - |
      # Wait for Elasticsearch to come up
      slept=0; while [ $(curl -s -o /dev/null -w "%{http_code}" http://docker:8020/) != 200 ]; do
        if [ $slept -gt 120 ]; then
          echo "Elasticsearch didn't come up after ${slept}s"
          exit 1
        fi
        sleep 5; slept=$((slept + 5))
      done
      echo "Elasticsearch came up after ${slept}s"
    - docker-compose up -d coordinator lazo
    - sleep 10
    - docker-compose up -d profiler apiserver apilb test-discoverer
    - |
      # Wait for profiling to end
      slept=30
      sleep 30
      while [ "$(curl -s http://docker:8012/metrics | sed -n '/^rabbitmq_queue_messages{.*queue="profile".* \([0-9]*\)$/s//\1/p')" != 0 ]; do
        sleep 5
        slept=$((slept + 5))
        if [ $slept -gt 240 ]; then
          echo "Profiling didn't end after ${slept}s"
          docker-compose logs profiler
          exit 1
        fi
      done
      echo "Profiling ended after ${slept}s"
    - docker-compose ps
    - docker-compose logs profiler

    # Run the tests
    - |
      # Run tests
      if ! python -Wd -m coverage run --branch tests/__main__.py --verbose; then docker-compose logs apiserver; docker-compose logs lazo; exit 1; fi
    - docker-compose logs apiserver
    - docker-compose logs lazo

    # Generate coverage report
    - docker-compose down -t 30
    - ls -lA cov/
    - coverage combine -a cov/
    - coverage html
  artifacts:
    paths:
      - htmlcov
    expire_in: 1 week

python-style:
  stage: test
  before_script:
    - curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python - --version 1.0.10 && /root/.poetry/bin/poetry config virtualenvs.create false
    - /root/.poetry/bin/poetry export --dev --format requirements.txt >reqs.txt
    - pip --disable-pip-version-check install --constraint reqs.txt flake8
  script:
    - flake8 --ignore=E731,W504,W503,E501

frontend:
  stage: test
  services:
    - docker:19.03.5-dind
  before_script:
    - curl -Lo /tmp/docker.tgz https://download.docker.com/linux/static/stable/x86_64/docker-19.03.5.tgz && tar -xf /tmp/docker.tgz -C /usr/local && rm /tmp/docker.tgz && export PATH=/usr/local/docker:$PATH && export DOCKER_HOST=tcp://docker:2375
    - docker info
    # Important note about this: the Docker server is on a separate host,
    # so exposed ports are at 'docker' not 'localhost', and
    # Docker containers can't reach the local runner!
  script:
    # Build base image, using the GitLab registry as a cache
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN registry.gitlab.com
    - |
      # Pull the base npm environment
      docker pull $CI_REGISTRY_IMAGE/npm || true
      # Update the base npm image (maybe)
      chmod 644 frontend/package.json frontend/package-lock.json
      touch -t 200001010000.00 frontend/package.json frontend/package-lock.json
      docker build -t datamart_npm . \
        --cache-from=$CI_REGISTRY_IMAGE/npm \
        -f frontend/Dockerfile \
        --target=build
      # Push the updated image to the registry (might be no-op)
      docker tag datamart_npm $CI_REGISTRY_IMAGE/npm
      docker push $CI_REGISTRY_IMAGE/npm

    # Run the frontend tests
    - docker run --rm datamart_npm sh -c "CI=true npm run test"

k8s_configs:
  stage: test
  before_script:
    - curl -Lo /tmp/kubeval.tar.gz https://github.com/instrumenta/kubeval/releases/download/0.15.0/kubeval-linux-386.tar.gz && tar -xf /tmp/kubeval.tar.gz -C /usr/local/bin kubeval && rm /tmp/kubeval.tar.gz
  script:
    - kubeval --strict contrib/k8s/*.yml

pages:
  stage: deploy
  before_script:
    - curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python - --version 1.0.10 && /root/.poetry/bin/poetry config virtualenvs.create false
  script:
    - /root/.poetry/bin/poetry install
    - (cd docs/ && make html)
    - cp -r docs/_build/html public
    - curl -Lo swagger-dist.tar.gz https://github.com/swagger-api/swagger-ui/archive/v3.23.0.tar.gz
    - (mkdir public/swagger && cd public/swagger && tar xf ../../swagger-dist.tar.gz swagger-ui-3.23.0/dist --strip-components=2)
    - python3 -c 'import json,yaml; json.dump(yaml.load(open("docs/schemas/restapi.yaml")), open("public/swagger/restapi.json", "w"))'
    - cp docs/schemas/query_input_schema.json docs/schemas/query_result_schema.json public/swagger/
    - sed -i 's|https://petstore.swagger.io/v2/swagger.json|./restapi.json|g' public/swagger/index.html
  artifacts:
    paths:
      - public
  only:
    - master
